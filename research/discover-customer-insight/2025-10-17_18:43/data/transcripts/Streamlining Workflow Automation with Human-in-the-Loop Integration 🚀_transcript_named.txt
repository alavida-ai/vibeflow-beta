# Streamlining Workflow Automation with Human-in-the-Loop Integration ðŸš€
# Processed with custom speaker names
# Generated by Vibeflow Speaker Identifier

alexander: um so i'm trying to like abstract away as much of the complexity as possible so you basically use compile you just run like a thing you just run like the initialization and then you write your files and you just run like a compile like compilation service um so this is all gonna do it by itself i like we don't really give a about this i can make this a lot simpler to use but just

william: just yeah sorry just this question on this so so you're you're right now triggering a workflow .md file and this gives it instructions to follow separate let's say md files or separate

alexander: prompts well it depends on the md files so you could basically what i'm trying to do is i'm trying to say okay what william is really good at is thinking through like the questions to ask giving the data it needs to kind of generate these strategic documents right like that's like step one the onboarding thing so you should be focusing entirely on that right and then you should be working with an nlm on the side to kind of allow you to to do so right the human aspect the human aspect right so if i go into this cursor agent now because what i've done is i've created it doesn't really matter but i've created my own mcp and it's hosted immediately after you initialize it so you'll see it here it's called vibe flow right um and then we could be like okay let's check like let me turn off a few of these because rust is not going to have good performance too many um okay let's check out our workflows or something right and then we have kind of like this workflow template that i added here which looks like this you know it's the same one we had before right it's like let's talk about the tools it's going to use and all that kind of stuff um that's pretty much it right and then we have like the template file of like how we expect our outputs to look like right uh which looks like this right so this is pretty much the entire like shindig um and it's going to talk about like the different workflows you're available and it's parsed it for you and that kind of stuff and you're like okay let's start um workflow two right and what it's basically going to do you can kind of define it in the prompt if you want to but it's essentially going to know what to do so it's kind of it's like it's going to plan out like how to essentially go through the different steps with you and then it's going to decide like pull in the prompt and it's going to plan out in front of you like how it's going to do it and what tool calls it's going to use and it's going to ask you for input so you have that kind of like orchestrated human loop kind of aspect coming in so like i'm going to do my own personal website for example um and you can create these prompts to be like as automated as possible or as huge in the loop as possible so if you want it to be like super huge in the loop and it's asking you every two like two seconds like questions so it gets as much of your input as possible then that's fine and it's going to use like the different tool calls and that kind of stuff from your um like here it's using perplexity and it's researching it all from this prompt right and it's basically going to go down and kind of iterate through this workflow along your side so you don't get kind of lost pretty much sorry good yeah

william: just just like so this is all this looks good but a few questions on my end just based on what you're saying um does so we talked about i think it was last week or maybe a week and a half ago about smaller prompts maybe not super small but like individual prompts

alexander: uh

william: will provide uh more depth in the output versus let's say cramming everything in one big prompt right you're gonna get everything but more on a general surface of the point of view yeah

alexander: is

william: that i don't know if that's considered a context window or not right but does this with this workflow does it still kind of let's say uh separate prompts to get the maximum output

alexander: yeah that's exactly what it does it's basically like our most granular prompt is this as we mentioned like you have like the steps of prompts that go down right like this this is a very like this is the whole workflow and what we used to do is just inject the entire workflow and kind of pray but what i've done is i've created like this like data structure that essentially like if you say like next step right so if you say vibe flow next step it will like tell you like what is the next prompt right what tools you should use from it and like what input you kind of need to go down it so it's doing it on that prompt by prompt basis so it's super granular and you can define it as granular as you want if you if this workflow has like eight different steps it's still going to do it step by step and okay it's going to make sure that it gets like the right feedback from you it's going to make sure that you're happy with the output it's going to make sure it uses the right tools all the way on the way down pretty much right so you can see how it's done step one then it said it updated the status of the first step saying step like step one's now done right you can even make it much more human loop by just i'll just do the down purposes i said like do most of this yourself and then it's getting the next step

william: so so in other words and correct me if i'm like to tell me if i'm saying this correctly it's it's uh the prompts are like it's still treating it as separate prompts but this workflow chains together each prompt like each kind of prompt in let's say in in a in a logical way right however it will whatever order that we replace these prompts and then and this workflow

alexander: absolutely yeah and still going to ask you for like information and all that kind of stuff if you want to make it more human loop like and you want to have like i don't know add extra information like uh as we mentioned before uh the data stuff which is the the swipe files like transcripts all that kind of stuff where you need to ask you questions then it's going to ask you for that information pretty much here so like what i'm trying to do and how i kind of made this system is so you don't need to think about any of the bullshit like the cursor rules or of like kind of like it outputting random files or it uses the wrong files all that kind of stuff you basically focus on what data it has what questions it needs to answer how it structures the output and then it literally just works with you on the side here pretty much um and like you just get like it gets like significantly better outputs i find personally and you will see if you find the same thing than uh chucking everything into context pretty much right and there yeah sorry guys sorry

william: i

alexander: i

william: i i'll go go ahead i'll i'll tell you after no

alexander: that's fine that's fine

william: it's doing

alexander: so

william: so like there's this is something i'm still experimenting with and i think once once i get to kind of i don't know maybe to the content even after the content generation i i think after this first kind of like phase of this mvp of like you know we got brand fundamentals we've got the comp analysis we've got the content strategy we've got the content generation once we get to that like end at that point i'll have let's say a good i already have an idea right now but with cursor like for example like what i'm trying to say is is this all like like i see on your cursor screen right now i see cloud force on it is there a way that's depending on the phase or the prompt i'm using different llms yeah

alexander: yeah you can absolutely but like

william: without manually doing it like it just triggers and and switches to the llm like basically each prompt is assigned a specific model

alexander: yeah you could do that like you could do that either here pretty much like in the file system and be like you know just model or whatever you want to use like to be honest though you do you do lose quite a bit of i i get what you're saying though like gemini might be better for like foundational research you want to use um you know grok for different kind of workflows that kind of stuff i i might avoid doing it per workflow because you lose the context if that makes sense like a large part of this is like you're basically incrementally getting better and better as you go down because this context is now in and if you swap over to the next one it loses context with that said though if you have a sub workflow like this one for example content strategy and you just say which model you want to use it will use the right model right um and it will have context of the previous output if that makes sense okay

william: that that's a very good point because if that's how it works because i see it like like you're saying that using one model basically uses like like it takes the context of that model switching to another model we have to kind of redo that the context refreshes to a blank slate until it builds up again right yeah now now does it is context everything that you see as output or is there a context in the background that we don't see

alexander: no everything you see as output as context there's definitely some context happening around like for example here it says read template .md right so what it's done is that it's actually just read those templates it's read this one and it's read that one and now it's actually output the documents in the right places um so this template part right here would be context but you wouldn't necessarily see it you know that it's been pulled in like you can see the context exactly what's been pulled in um but you don't really see the chat but

william: what about what about thought like you like you know how you have read we have thought

alexander: yeah thought you know

william: thought thought is context so this is so so so this in my my view that's background context that we don't necessarily see as output but it's still kind of context so would you see that that thought background context is just as important as the output context i

alexander: i would say that like okay when it's like this where it's just thinking about next steps not really but there's like thought that it does off the back of a perplexity search for example which i think would be quite important um because it's gonna you know especially when we start adding the ability like as i mentioned to kind of use personalities right like prompt the actual system itself it's going to ask questions in a different type of way and it's going to output it as thought and that's really going to change like what you're kind of getting out of the entire thing if that makes sense

william: yeah yeah but like like like for example sonnet 4 is good for certain things i find writing creative writing like outplayed is sonnet 4 is good um like again like like a big reason why last week i spent the time working on the same prompt for let's say comp not comp analysis um brand fundamentals it was like four models i used right it was grog 4 gemini 2 .5 open ai 03 and sonnet 4 right and then i started ranking and started to read through it right and like like i mentioned 03 was the best right and then uh sonnet 4 is pretty good right and i guess sonnet 4 is probably the best in terms of it's cheap and good output right but like if i if i don't care necessarily about spending a little bit more money on tokens for a much better cleaner output like i'll like it's a no -brainer spend the money right um if if if quality accuracy and just top tier outputs is the most priority which it is for me that's that's like the best that that's that's the that the highest priority thing is is is um outputs i i would i would even uh maybe not right now but i would even like do some tests with opus because opus can be very very good and i've used opus a few times for creative stuff it's actually like i'm like really good but it's also very expensive apparently that's what they say and i yeah so the question is is that how can we if we were to switch llms how can we almost like you know also provide the context of every llm almost as if it's like this um you know kind of like and like the the image i'm thinking is one of those like like if you have an ice tray you know like to make ice right and you have like one ice ice cube tray right you have one ice cube slot that's context for sonnet but then that spills over to the next one and then when you switch llms to let's say oh three or gemini right so the context is always there and it's accessible between models do

alexander: you um do you see a use case for example in this workflow file right where you would have the need across different sub prompts to use different models

william: well uh for this specifically um i have to review because i have to like review everything but i imagine this is there's a lot of overlap to like the process that uh like i'm working on in terms of brand fundamentals for example like pure foundational brand stuff right that you need to to build up the the i think eventually the the content so yeah like like for example this is how i see it it might change but brand fundamentals right now maybe i have to do more back testing and see if oh three is really maybe oh three was just really good that one time right but let's say for a front for just this example oh three for brand fundamentals right let's say for content uh comp analysis uh comp analysis and again i mean i i don't know what the model is right now but let's say just for for for for for argument's sake it's uh gemini 2 .5 it's just the best for comp analysis right and then um and then when we get to content strategy maybe that is uh maybe that's sonnet 4 right or no you know i forget actually let's use sonnet 4 for for for content creation let's say content strategy it's grog 4 right so i've got best ai that best model for specifically brand fundamentals best model for comp analysis ends up being gemini 2 .5 let's say best model for um content strategy which is now like the foundations or the content generation let's say that's grog 4 then content content content generation is sonnet 4 right so not to say that if i use the same model throughout whether models yeah i'm gonna get pretty good output sure right but like like if i'm if if the north star for me for for building this at least one of the big kpis is like can i get the best can i identify the best model for the specific workflow phase right um for me that's an optimization that is i know there's optimizations you do after but i think this is a one optimization i would say this is good to do while also building up this process yeah

alexander: i mean there's nothing to be honest stopping us from doing this now right um because if we just like let me just list this out real quick uh if we see that like the next workflow for example is content strategy like now we know that the the our ai system has an understanding that we need to go through the content strategy workflow right so there's nothing really stopping you like in the short term like to just literally just do a gemini and be like okay let's do the next workflow right but

william: but will this will this still have the context of the previous yeah

alexander: because what is doing like the whole system that i've just built right is that it's literally outputting like if i do a next step for you right it outputs like what the dependencies are here so it's the first thing it's going to do is going to read like the previous output here that kind of because content strategy is dependency of brand fundamentals it's going to look at brand fundamentals output first under see right here to get context i'll read the specified files i'll put that mdn strategy then i will create a new file of the objectives right so it's like it's all built in like that so you don't need to like reference it and have all that kind of shithousery going on um it will have so it's the context so

william: so so so is is the work around that or like maybe the solution is that when we do this it has to be the same session

alexander: no we don't have

william: to

alexander: do this i i just change sessions right there

william: so

alexander: how do you

william: get the so so if you change the model you change the session how how do we get the like all the context all that work that we did for to getting the model to get the context yeah we don't want like like that's for me like i'm sure for you too it's it's a very important stuff right yeah

alexander: yeah

william: like how do we not just kind of like throw it away or disregard it how do we use that because that's that's work that's

alexander: that's a valuable

william: insight

alexander: sorry i see what you mean i see what you mean um you mean in terms of getting the actual thought processes as as opposed to just the output right

william: well that that's why i asked is that background thought process is that good enough context for that to not be wasted or is it just output that we care about i

alexander: know output

william: could be probably and maybe it's not 50 50 it probably isn't right maybe it's again you you know better than i am i'm just thinking it has to be something where like maybe i'll put it's 60 or 70 but that 30 context and background could also be a decent amount again i don't know if it's 30 i don't know if it's 20 maybe if it's five percent then it doesn't matter it it's not worth it but if it's like 20 25 and again those those those optimal those those back made that could impact the output in a meaningful way so the question is i i don't know what those ratios are i don't know if it actually makes a big difference it but it's worth exploring if like like like if you have any insight on that

alexander: there's a way around that right where you don't need the context session we spoke about this the other day um by putting in the template and putting in the prompt that in the output you want reasoning because what you're trying to capture with the thought process right and this is where like it's pretty important when you do the ai personality aspect so we create like the world's most correct vibe marker or whatever you want to call it and and and we say like this vibe marker is going to follow the rules of um the fundamentals of marketing book all that kind of stuff right so it has a personality it has a way of thinking and that's reflected in its thought processes do we both agree on that sorry like do we both agree on that like on that on that like hypothesis that if we you

william: mean you mean you mean the llm personality

alexander: yeah the llm personality will impact the thought processes and 100 yeah what we're discussing is like the importance of having those thought processes as context for like downstream workflows right because then it has like how it got to that point

william: yeah and again i'm not saying it does not i i i just want to make sure that we're not uh overlooking that if if it does make impact yeah

alexander: i think it does make an impact but i think the way to get around that is to ask it in your template and your workflow to output its thought process and reasoning as to why it came to a conclusion slash an insight because then that would be captured in your output and if you ever want to make those documents like those output files for example if you ever want to make them customer facing so you put them in the hands of customers you just prompt a like you know you just prompt it to remove all the reasoning and make this like much shorter as you mentioned they don't even read your strategy to files anyway so you have to kind of deliver in a format that's much more in line of them so i would just prompt them to do it in in a customer format way but yeah the output should contain your reasoning if you want to have that capture a downstream workflow

william: so so for example like you go to brand fundamentals there's some sort of logic reasoning behind it would it be like just in terms of like how it'd be built out would it will there be one output file of the actual output of the brand fundamentals those phase one two three that for the brand fundamentals when that you know whatever the prompt you know instructs it to do and then another md file for example purely it's just raw thoughts of of that context of how it arrived to

alexander: that i would i would use one file for now um not even that you're losing anything from that i think it just makes it a lot more clear to you as to what that the thought should be associated to an output right like positioning statement for marketing agencies you need to scale operations okay if you just had under their like related thought right or like how we came to this conclusion when you read down it and proofread the entire thing it's going to make a lot more sense to you as to how it came to that conclusion but if you have like another file to the left and it's just outputting thoughts which by the way we can easily do i don't see the advantage of of that to be honest i don't see how that improves downstream workflows and i don't see i think we lose more by not putting it in the output at the moment okay

william: okay okay so so that the context is still in the output file it's just more of like maybe okay got it okay um and then it once i switch llms it's based all those llms are now taking the different output files from what was previously prompted yeah

alexander: that's exactly it that's exactly

william: it and then and then by doing it that way is there any sort of gaps that these llms are missing through context no

alexander: no no okay well i mean because the output file is what i just imagine handing that to a third party person who has no context of what's going on yeah yeah okay so with that in mind i think there shouldn't be any hidden because you lose uh traceability right there's going to be decisions that you or like insights that are made if you just pass sessions over right where it has the entire thought process and we can't really dive deep into why it got to that conclusion it makes it super hard for you as the marketing operator to debug your workflows if that makes sense right because you're like you're kind of doing a different version of what i'm doing right like you're going to get down to like content strategy but like okay why the fuck did it decide to to you know use this um this content pillar or whatever right and then you go back to the previous brand fundamentals output and you might see that it's like like there's a thought process in the output that talks about you know one of the content pillars that might be a good idea whatever right or target audience is going after it that makes it easy for you to debug but if you like past sessions over where it's like hidden thought processes that it's just impossible for you to understand how gain to the output so we should really focus or aim to have everything in a single output file for four years for your sake pretty much

william: okay okay one one output file so it's like like like depending on each workflow it's still one output file

alexander: yeah i i think that's we should structure workflows around a single output file

william: okay interesting no

alexander: sorry that's wrong that's wrong we should structure a sub folder here based off of the single out because what i what i did here is that we have a comp analysis that was created as well as the brand fundamentals in a single workflow right because i'm just being lazy but i want to give you also the ability to just like do both right like you might have i don't know you might not really give a about this client or whatever you just want to do all of it in a single workflow you just put the workflow at the top of the directory and it'll output everything across all the different subfolders

william: but sorry go ahead no i was going to say so like just so i'm clear is it one folder called output and then in the folder you have the different outputs of brand fundamentals content comp analysis and stuff or is it just one output .md with brand fundamentals inside of it comp analysis content strategy etc

alexander: per folder can you see my screen right now yeah per folder you'll you'll have a single output file

william: so and then and then one folder would be the stages of brand fundamentals comp analysis

alexander: um one folder read the stages of brand can you i i'm not sure you got that question sorry like

william: like like okay i guess the question is the output md is the output of what is it specifically per phase like brand fundamentals has an output .md or is it output .md as one file and as we go through the workflows it just updates the output file with the new information based on the prompts right

alexander: in the workflow i get what you mean um so it's the output md reflects the template and the workflow combination within a single folder so i i'll write this down to make it more clear i'll send you i'll send you over the docs later on but basically if you define in a subfold like each folder right defines an output that you want so we have a strategy folder it should be called brand fundamentals um we have a competitor analysis one and we have a content strategy one each folder defines that i want an output called content strategy i want an output competitor market analysis i want an output called strategy or brand fundamentals right and then all you gotta do is define the template and the workflow to get there and then you just have the chat with the lm with the hue in the loop to get and then you get the output if that makes sense so you're going to get one output md file per sub folder per folder okay

william: yeah so so so it starts with the workflow md and the template md and then once you get to that stage once it's done there should be an output md that's created which is the combination of the template md and the prompt md exactly like the interaction that's exactly okay so there's so there's three there's three files per folder and each folder represents a phase

alexander: yeah yeah yeah exactly because i what i'm trying to do is i'm trying to give you full autonomy to define anything the you want to make right it doesn't have to be content strategy it can be whatever you want right and define like how they're interrelated to each other and define how you get there and what they look like right because we already identified like we want to have personalities templates we know the value of templates because you've already said hey i want this in a table but you know open ai does a table sometimes but grok doesn't which is like that we can't that that's too much uncertainty so you define a template that says output the findings in a table right and then the workflow is really where your skill set as a marketer comes in where you define the phases that goes down right which you've already created these workflow files by the way you've shared them with me it's it's exactly the same thing you would just take that workflow file and you'd put it and quite paste it into this workflow .md and you'd get the exact same kind of output pretty much um and then you just just have a chat with the lm on the side and it deals with all the about mapping dependencies making sure that it uses the right template and make sure that outputs in the right place all that kind of stuff through its own custom mcp and then so your only focus is that and then going through it the chat with this so you might as well just see this and it would make no difference to you

william: so then do you like for example like brand fundamentals let's say just real world you do brand fundamentals let's say i use o3 i've got my i've got a folder called brand fundamentals i've got a template that i've created and i've got this prompt right yeah uh nicely structured it's like super clean organize everything right once that's done do i make another folder called comp analysis and then i already have my template and i have my prompt maybe i have to adjust a few things client name website you know obviously competitors etc like those changing variables but then do i still manually trigger that phase two which is if phase one is brand fundamentals or let's call it step one brand fundamentals step two comp analysis um do i have to manually trigger on step two my my my workflow saying hey like use use this template whatever the prompt is to activate the actual real prompt of of comp analysis using the template of comp analysis to provide me the comp analysis no

alexander: you it the the system i created will have context to that it'll know that all you go so it doesn't automatically automatically completely automatically it i mean from a technical perspective it creates this whole like dependency graph thing under the hood and so it just knows what's dependent on other things so like if we were to create a new folder for example um i don't know i call it twitter content analysis which i know you would never do i think you mentioned you would never do that but like i like for the sake of the example then in this folder you should have a template .md and you should have a workflow .md and like both of it would like will defy like this is the workflow for twitter and then obviously you'll be a lot more you know um yeah insights go here right then your only job now is and yeah to be honest you know i can actually make this a lot easier to do as well um let me just see this so i gotta remove this i actually haven't tested of gemini yet so i got tested gemini your your only job is literally just to run like a single command which i can easily do it so the lm does it for you so you wouldn't have to give a shit about this um but basically what it's on it's the system has found your kind of like workflow or your new workflow and it's part of the loop so you just kind of go like next step and it'll kind of figure its way out to to be able to generate your twitter content strategy um that's it like you don't really need to deal with anything your only responsibility now moves to defining the personality the template and the workflow um and then having an actual chat with the lm so that you still get that human loop aspect uh and i'm also building it in a way where like if you don't want any human loop and you're super confident in your prompts down the line then you literally just be like yeah try this workflow and it'll just go down the entire thing through like

william: do you do you still have to do the run tool manually the

alexander: run tool no i got rid of that

william: you

alexander: did yeah how do you get how do you do that i have no idea they updated it i think they just updated it to remove it it just started working one day and i was just like oh thank you god like you saw i didn't do any of these tool calls i just did it

william: was this reason oh it says i see cursor restart to update i guess there's an update that does this this is like a new thing i hope so i hope so okay that's good that's nice um okay i i got four minutes how do you want to do the twitter thing

alexander: uh i'm going to send you an mcp link uh try and implement it um i'm i'll be on for the next six hour uh next four hours so if you want to uh add it i'll just give you instructions to add it um and then if you're not able to figure it out i can jump on a call again uh tomorrow or later this evening up to you

william: do do i have um do you have four minutes to like like can this be four minutes at least half of it if i share my screen like like are we able to do this uh i

alexander: have definitely a four minutes let's see if we can get it done four minutes you downloaded docker or docker right um

william: i think so yeah i do i do have it so

alexander: i'll just send it to you on slack so you can add it to your mcp okay

william: so to do that do i go to cursor i go to settings uh

alexander: yeah so you go to cursor settings you share your screen with me real quickly

william: yeah screen

alexander: there we go share your screen can

william: i go to settings profile cursor

alexander: settings you go into the top right corner there in your chat interface oh okay no you you're good you're the right one uh tools integrations then you press on add custom server call your pace what i just sent you pretty much before before the yellow bracket

william: here

alexander: yeah just add a comma after that um red bracket right above you like that yeah and then you can quite paste it go and remove the last comma at the end of it it's it's super picky then you command save done and then uh get cut off and then just see so if i do i would just close cursor settings and open up again so go into cursor settings uh right right right yeah they're gonna close it and then open it up again to the top right corner um in your chat interface area oh

william: sorry i think they're on one settings this cursor settings i just check it if it's there oh it's not here yeah

alexander: why it's not showing up uh can you click on new mcp server again please should i restart

william: my cursor

alexander: uh so scroll up let just see if it's uh okay that has to be above the red bracket sorry the one um the one right above you yeah so just copy paste the twitter assistant stuff there we go all the way down to the bottom of the red bracket yeah and then just move it right above that red bracket so comma after that blue bracket nice perfect and then copy paste so here yeah oh

william: nice

alexander: and then uh

william: oh hold on i gotta copy this again

alexander: yeah and then just remove the brad the comma after the the that one yeah and then add make it from here beautiful and then command save oh i think oh

william: this this still

alexander: had it yeah add another bracket add

william: another bracket

alexander: yeah like

william: this

alexander: yeah

william: is this correct

alexander: uh is that correct actually just press tab that you're good i think you're good yeah yeah command save then go back to cursor settings loading the tools

william: loading tools so this what is loading tools means it's just like like loading tools

alexander: yeah i mean i mean it should be if you just uh toggle it off and on again like that little red oh there we go cool actually

william: i i got 10 minutes like he said okay perfect okay cool perfect okay cool that's fine um okay so enable this should uh should i oh there you go cool nice okay cool nice so and then if i go to okay let me just like delete all the not delete but

alexander: so i would add a create a new chat session

william: and let's like just

alexander: say um let's get let's find a twitter handle that you're happy with okay

william: let's just use let's just use this one copy network for now so like okay so here's the twitter handle um does it matter which what would you suggest because like i don't need like do i need it doesn't matter if i get like an expensive model or not for a first creature to scrape and probably the cheaper the better because it's just scraping well that's what

alexander: we used to just that model is not going to scrape anything the models are going to scrape stuff are on my servers um so you're literally just using a model to trigger the mcp workflow that's all so close a lot of force on it with thinking would do fine like because it'll just like i find it to be the best one for training workflows um in terms of a twitter handle do you have a do you have a preference or do you want me to send you one

william: yeah like this this is like the copy network twitter handle this is just um this

alexander: is

william: just a test so like like like i like i don't go full steam like maybe just like the last i don't know it's 10 days just just for a test

alexander: okay say uh can you use the twitter scraper to extract the last uh 10 days for climate network

william: that's it like should should i say anything else or oh actually it's just a twitter scraper so that's good okay so just yeah we're good um so

alexander: you had it here sorry go ahead can you open it up just to see what the tool call looks like and

william: open well what

alexander: do i where am i opening uh where i said called extract username you should see if it oh came back okay cool i'll be writing in a few minutes tell the user how to check our table cool so so is this is going

william: to your air table

alexander: um yeah because i think we need to still hook up yours uh okay so it's only extracted eight tweets right so far but give it some more time i think extract the rest of them oh cool okay

william: so so how do we so like for you like i guess

alexander: is

william: this in your air

alexander: table to make sure because i think i hooked it up to your you sent me an air table right

william: yeah i can we send you the id and stuff if you can so or we can do it right now i got five minutes yeah do

alexander: you want to rerun this just to see can you like get well get the latest akave tweets yeah in the same session or new session same session is fine just want to see more coming in

william: should i specify the last five days

alexander: uh but yeah you can if you want to actually i think there's only like four tweets in the last or two from the last five days from looking at

william: okay so like 14 days

alexander: if

william: i say can you catch isaiah can you can you scrape

alexander: can you script in like 14

william: days

alexander: because what it's doing it's converting into it's basically do it by a number um at the moment it's gonna last 100 or some but then it pulls in the timestamp and then it's then you can do it you can like get it by the last 14 days once it's scraped in if that makes sense um but i can actually probably add that as an input workflow to be honest with you this if you prefer doing that you prefer to scrape by timestamp or you prefer to scrape by number i'll just give you the option yeah

william: i guess i had

alexander: to like kind of

william: play around with it to see what would be better but

alexander: if you say can you get the last 14 days of akave tweets it'll be able to get the last 14 days for you

william: yeah i'm just thinking maybe like maybe it's better to bite date like can you get like the tweets from let's say march 1st of 2025 because because if i say because if i go by date from let's say march 1st 2025 to to now i also can get analysis or maybe maybe a better reading on let's say cadence of when i say cadence i mean cadence of posting i mean how many times they post a week for example

alexander: gotcha uh what would what would be the downside of saying get like the last 500 tweets and then querying by by date you could do that too yeah because i think that's how it's structured at the moment you can query by date um

william: yeah that's fine i

alexander: mean it

william: really depends

alexander: it's either

william: way it

alexander: works you know it's not a so run this yeah you can you run that and see how it happens it's running the it's running the oh you said scrape okay never mind um well

william: so if i see scrape that that's not as

alexander: good as get well yeah it's going to scrape it if you say if you say get like it will fetch it from the our table or a query would probably be the best one but now let's see now it's queried it pretty much yes if you say something like get like the top performing tweets and compare it to the lowest performing tweets see what happens i might need to change a little description so it's very clear that evs is a comparative metric can i see the uh can you open that up please the call search analysis table uh nice let's go to the scroll over to the right so you see how it's getting tweets that have like a score above six so yeah that'll be your higher performing ones and then the other ones if you run run the tool it goes below let's open that one up let's see what's an evs lower than two okay

william: maybe like lower than five or lower than six

alexander: yeah i mean one thing i want to add i probably should add a distribution so you kind of have an idea of it right like you can see like the percentage of tweets where they land right um so like 50 tweets have like an eva because evs is unparallionated it's not based off of the weight of all that tweet with it all the tweets within a single profile it's just like a general score across all profiles it makes sense

william: but but but is it taking okay right right so that'd be like an extension or some other score that takes all the context of the evs's and puts like a percentile by based score

alexander: yeah i could i could i could oh uh i could do that as a tool call i could do that as a tool call that's fine i could do that as a tool call you

william: know what you know what what so like let me let me play around with this um because and i'll write some notes on on on like what would be good like what what maybe some ideas to you know based on the purposes applications um how do i how do i so i can okay so it's prompting stuff here but it's just going to because like i remember you show it i gotta go but i remember you showing me an air table where like it was like it was basically all the it was the scrape

alexander: yeah right it was the actual scrape it's communicating with this air table it's the same air table

william: okay is it possible that that this outputs can go to the that the account i made so i can play around with that data yeah

alexander: i mean i mean you can play it around like the data now like whilst i move it to your air table because you still have access to it through my air table but i'll move it over and migrate it over to your air table as well so you'll have the same data in that that new air table of yours and i'll send you over the details uh okay so so you're going to send me a link to your air table in the meantime well you already have you have access to it right now through this oh oh you want to see the actual air table itself yeah yeah like the actual script yeah i can i can send you that right now uh before you do um yeah try try some shit out like and and see how try running a workflow with it through a workflow file like add it as a tool you know how we say perplexity like use this as your own tool because this is when shit gets pretty like crazy it's like when you start creating your own tools and you're like oh okay let's extract like the best hooks in this username whatever uh and then you have like a hooks workflow whatever the fuck it is so this is where things get no this

william: is this is gonna be very interesting i i got a lot of ideas about this this is gonna be amazing this this this twitter thing so okay cool i sorry i gotta go i'll message you please send me the air table uh link so i can kind of look at what i scraped and stuff like and and and and like if i make a new session and i do another scrape right which i plan to do i have to do you have to give me that link or is there a way i can navigate and find which which air table pertains to my session

alexander: it will all be on the same air table for now uh then what i'm gonna do is i'm gonna move it over to a new air table and give you like the same docker link that i gave you and it'll just be all in your own air table session pretty much but i can literally do that in the next like 20 minutes so okay

william: awesome awesome sorry alex i i gotta go you're good uh

alexander: but thanks i appreciate

william: it we'll we'll talk we'll talk uh uh i'll find sounds good

alexander: uh

william: take

alexander: care

